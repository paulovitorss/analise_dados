{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importe as bibliotecas necessárias",
   "id": "bc14dafce2caf907"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Instalando as bibliotecas necessárias\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install pymongo\n",
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install wordcloud\n",
    "%pip install spacy\n",
    "%pip install matplotlib\n",
    "%pip install numpy==1.26.4\n",
    "%pip install -U scikit-learn\n",
    "%pip install unidecode"
   ],
   "id": "7f2d74b00c76fd40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T02:16:42.159143Z",
     "start_time": "2024-09-06T02:16:42.155399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importando as bibliotecas\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "from wordcloud.wordcloud import STOPWORDS\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import unidecode\n",
    "from db import connection_db as conndb\n",
    "from db import filters"
   ],
   "id": "4761db26da7a2327",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T02:16:43.899647Z",
     "start_time": "2024-09-06T02:16:43.893647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mongo_connection = conndb.MongoDBConnection(uri='mongodb://localhost:27017/', database_name='dadosVivamente', collection_name='dadosSemFiltros')\n",
    "mongo_connection.connect()\n",
    "db = mongo_connection.db\n",
    "collection = db.collection"
   ],
   "id": "7a6bb32be9aeb75a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão estabelecida com sucesso ao banco de dados.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T02:16:46.354363Z",
     "start_time": "2024-09-06T02:16:46.350620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collection_filters = filters.CollectionFilters(db, 'dadosSemFiltros', 'dadosComFiltrosIniciais')\n",
    "filtered_collection = collection_filters.apply_pipeline1()"
   ],
   "id": "ba5a47bd08e116ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleção: dadosSemFiltros\n",
      "A coleção já existe\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pegar apenas os documentos que possuem a data de criação do primeiro post com pelo 7 anos de diferença da data de criação do último post\n",
    "if 'posts7anos2anos' in db.list_collection_names():\n",
    "    print('A coleção já existe')\n",
    "    collection = db['posts7anos2anos']\n",
    "else:\n",
    "    # 7 anos em milissegundos\n",
    "    sete_anos_millis = 7 * 365.25 * 24 * 60 * 60 * 1000\n",
    "\n",
    "    # 2 anos em milissegundos\n",
    "    dois_anos_millis = 2 * 365.25 * 24 * 60 * 60 * 1000\n",
    "\n",
    "    pipeline2 = [\n",
    "        {\n",
    "            '$addFields': {\n",
    "                'firstPostDate': {\n",
    "                    '$toLong': {\n",
    "                        '$arrayElemAt': [\n",
    "                            '$posts.created_time', -1\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                'lastPostDate': {\n",
    "                    '$toLong': {\n",
    "                        '$arrayElemAt': [\n",
    "                            '$posts.created_time', 0\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$addFields': {\n",
    "                'diff': {\n",
    "                    '$subtract': [\n",
    "                        '$lastPostDate', '$firstPostDate'\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$match': {\n",
    "                '$and': [\n",
    "                    {'diff': {'$gte': dois_anos_millis}},\n",
    "                    {'diff': {'$lte': sete_anos_millis}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$out': 'posts7anos2anos'\n",
    "        }\n",
    "    ]\n",
    "    collection.aggregate(pipeline2)\n",
    "    collection = db['posts7anos2anos']"
   ],
   "id": "73d1de8544b1ca4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'postsComBDIAndInfos' in db.list_collection_names():\n",
    "    print('A coleção já existe')\n",
    "    collection = db['postsComBDIAndInfos']\n",
    "else:\n",
    "    pipeline3 = [\n",
    "        {\n",
    "            '$unwind': '$posts'\n",
    "        }, {\n",
    "            '$project': {\n",
    "                '_id': '$posts._id',\n",
    "                'idade': 1,\n",
    "                'sexo': 1,\n",
    "                'id_usuario': 1,\n",
    "                'nivel': {\n",
    "                    '$let': {\n",
    "                        'vars': {\n",
    "                            'dividedValue': {\n",
    "                                '$divide': [\n",
    "                                    {\n",
    "                                        '$arrayElemAt': [\n",
    "                                            '$respostas.nivel', 0\n",
    "                                        ]\n",
    "                                    }, 21\n",
    "                                ]\n",
    "                            }\n",
    "                        },\n",
    "                        'in': {\n",
    "                            '$cond': {\n",
    "                                'if': {\n",
    "                                    '$gte': [\n",
    "                                        {\n",
    "                                            '$subtract': [\n",
    "                                                '$$dividedValue', {\n",
    "                                                    '$trunc': '$$dividedValue'\n",
    "                                                }\n",
    "                                            ]\n",
    "                                        }, 0.5\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': {\n",
    "                                    '$add': [\n",
    "                                        {\n",
    "                                            '$trunc': '$$dividedValue'\n",
    "                                        }, 1\n",
    "                                    ]\n",
    "                                },\n",
    "                                'else': {\n",
    "                                    '$trunc': '$$dividedValue'\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                'pessimismo': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.pessimismo', 0\n",
    "                    ]\n",
    "                },\n",
    "                'tristeza': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.tristeza', 0\n",
    "                    ]\n",
    "                },\n",
    "                'fracasso': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.fracasso', 0\n",
    "                    ]\n",
    "                },\n",
    "                'prazer': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.prazer', 0\n",
    "                    ]\n",
    "                },\n",
    "                'culpa': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.culpa', 0\n",
    "                    ]\n",
    "                },\n",
    "                'punicao': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.punicao', 0\n",
    "                    ]\n",
    "                },\n",
    "                'estima': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.estima', 0\n",
    "                    ]\n",
    "                },\n",
    "                'critica': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.critica', 0\n",
    "                    ]\n",
    "                },\n",
    "                'suicida': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.suicida', 0\n",
    "                    ]\n",
    "                },\n",
    "                'choro': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.choro', 0\n",
    "                    ]\n",
    "                },\n",
    "                'agitacao': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.agitacao', 0\n",
    "                    ]\n",
    "                },\n",
    "                'interesse': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.interesse', 0\n",
    "                    ]\n",
    "                },\n",
    "                'indecisao': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.indecisao', 0\n",
    "                    ]\n",
    "                },\n",
    "                'desvalorizacao': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.desvalorizacao', 0\n",
    "                    ]\n",
    "                },\n",
    "                'energia': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.energia', 0\n",
    "                    ]\n",
    "                },\n",
    "                'sono': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.sono', 0\n",
    "                    ]\n",
    "                },\n",
    "                'irritabilidade': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.irritabilidade', 0\n",
    "                    ]\n",
    "                },\n",
    "                'apetite': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.apetite', 0\n",
    "                    ]\n",
    "                },\n",
    "                'concentracao': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.concentracao', 0\n",
    "                    ]\n",
    "                },\n",
    "                'fadiga': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.fadiga', 0\n",
    "                    ]\n",
    "                },\n",
    "                'int_sexo': {\n",
    "                    '$arrayElemAt': [\n",
    "                        '$respostas.int_sexo', 0\n",
    "                    ]\n",
    "                },\n",
    "                'quantAmigos': '$friends.summary.total_count',\n",
    "                'postMessage': '$posts.message',\n",
    "                'postStory': '$posts.story',\n",
    "                'postCreated_time': '$posts.created_time',\n",
    "                'diaDaSemana': {\n",
    "                    '$switch': {\n",
    "                        'branches': [\n",
    "                            {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 1\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Domingo'\n",
    "                            }, {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 2\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Segunda-feira'\n",
    "                            }, {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 3\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Terça-feira'\n",
    "                            }, {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 4\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Quarta-feira'\n",
    "                            }, {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 5\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Quinta-feira'\n",
    "                            }, {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 6\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Sexta-feira'\n",
    "                            }, {\n",
    "                                'case': {\n",
    "                                    '$eq': [\n",
    "                                        {\n",
    "                                            '$dayOfWeek': '$posts.created_time'\n",
    "                                        }, 7\n",
    "                                    ]\n",
    "                                },\n",
    "                                'then': 'Sábado'\n",
    "                            }\n",
    "                        ],\n",
    "                        'default': 'Desconhecido'\n",
    "                    }\n",
    "                },\n",
    "                'hora': {\n",
    "                    '$hour': '$posts.created_time'\n",
    "                },\n",
    "                'minutos': {\n",
    "                    '$minute': '$posts.created_time'\n",
    "                },\n",
    "                'diaDoMes': {\n",
    "                    '$dayOfMonth': '$posts.created_time'\n",
    "                },\n",
    "                'mes': {\n",
    "                    '$month': '$posts.created_time'\n",
    "                },\n",
    "                'ano': {\n",
    "                    '$year': '$posts.created_time'\n",
    "                }\n",
    "            }\n",
    "        }, {\n",
    "            '$out': 'postsComBDIAndInfos'\n",
    "        }\n",
    "    ]\n",
    "    collection.aggregate(pipeline3)\n",
    "    collection = db['postsComBDIAndInfos']"
   ],
   "id": "b2b9130a29aec5d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verificando se a coleção existe\n",
    "if 'postsComBDIAndInfosFiltroDataPosts' in db.list_collection_names():\n",
    "    print('A coleção já existe')\n",
    "    collection = db['postsComBDIAndInfosFiltroDataPosts']\n",
    "else:\n",
    "    # Primeira parte: Filtrar documentos com 'diaDaSemana' == 'Desconhecido'\n",
    "    pipeline4 = [\n",
    "        {\n",
    "            '$match': {\n",
    "                'diaDaSemana': {'$ne': 'Desconhecido'}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$out': 'postsComBDIAndInfosFiltroDataPosts'\n",
    "        }\n",
    "    ]\n",
    "    collection.aggregate(pipeline4)\n",
    "    collection = db['postsComBDIAndInfosFiltroDataPosts']"
   ],
   "id": "a3ca57322f7951d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pipeline5 = [\n",
    "    {\n",
    "        '$match': {\n",
    "            \"suicida\": {\n",
    "                \"$eq\": \"3\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$id_usuario'  # Agrupa por id_usuario\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$count': 'numero_de_usuarios_unicos'  # Conta quantos grupos únicos foram formados\n",
    "    }\n",
    "]\n",
    "\n",
    "# Executando a agregação\n",
    "resultado = list(collection.aggregate(pipeline5))\n",
    "\n",
    "# Obtendo o resultado\n",
    "if resultado:\n",
    "    print(f\"Usuários únicos: {resultado[0]['numero_de_usuarios_unicos']}\")\n",
    "else:\n",
    "    print(\"Nenhum usuário encontrado.\")"
   ],
   "id": "48f61f0a3eee0430",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Contando quantos usuarios são do sexo feminino e quantos são do sexo masculino\n",
    "pipeline6 = [\n",
    "    {\n",
    "        '$match': {\n",
    "            \"suicida\": {\n",
    "                \"$eq\": \"3\"\n",
    "            },\n",
    "            'sexo': 'F'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$id_usuario'  # Agrupa por id_usuario\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$count': 'numero_de_usuarios_femininos'\n",
    "    }\n",
    "]\n",
    "quant_feminino = list(collection.aggregate(pipeline6))\n",
    "print(f\"Quantidade de Usuarios Femininos: {quant_feminino[0]['numero_de_usuarios_femininos']}\")\n",
    "\n",
    "pipeline7 = [\n",
    "    {\n",
    "        '$match': {\n",
    "            \"suicida\": {\n",
    "                \"$eq\": \"3\"\n",
    "            },\n",
    "            'sexo': 'M'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$id_usuario'  # Agrupa por id_usuario\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$count': 'numero_de_usuarios_masculinos'\n",
    "    }\n",
    "]\n",
    "quant_masculino = list(collection.aggregate(pipeline7))\n",
    "print(f\"Quantidade de Usuarios Masculinos: {quant_masculino[0]['numero_de_usuarios_masculinos']}\")"
   ],
   "id": "400bb7399807879e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Filtro de 6 meses antes do mês da coleta",
   "id": "65a59d6b2a783f80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'posts6Meses' in db.list_collection_names():\n",
    "    print('A coleção já existe')\n",
    "    collection = db['posts6Meses']\n",
    "else:\n",
    "    data_inicio = datetime(2017, 12, 1)\n",
    "\n",
    "    data_fim = data_inicio - timedelta(days=6 * 30)\n",
    "\n",
    "    pipeline8 = [\n",
    "        {\n",
    "            '$match': {\n",
    "                'postCreated_time': {\n",
    "                    '$gte': data_fim,\n",
    "                    '$lt': data_inicio\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$out': 'posts6Meses'\n",
    "        }\n",
    "    ]\n",
    "    collection.aggregate(pipeline8)\n",
    "    collection = db['posts6Meses']"
   ],
   "id": "c4f207b8e88f2915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filtrando documentos com o atributo maior que 3\n",
    "filtro = {\"suicida\": {\"$eq\": \"3\"}}\n",
    "documentos = collection.find(filtro)"
   ],
   "id": "ea19f91952d67bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Transformando os documentos em um DataFrame\n",
    "df = pd.DataFrame(list(documentos))"
   ],
   "id": "8e80f1ac50e27240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['data'] = pd.to_datetime(df['postCreated_time'])\n",
    "df.head()"
   ],
   "id": "e5d547867db365ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.dtypes)",
   "id": "7cb7d55ccefa2446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lista de colunas que precisam ser convertidas\n",
    "colunas_para_converter = [\n",
    "    'pessimismo', 'tristeza', 'fracasso', 'prazer', 'culpa', 'punicao', 'estima',\n",
    "    'critica', 'suicida', 'choro', 'agitacao', 'interesse', 'indecisao',\n",
    "    'desvalorizacao', 'energia', 'sono', 'irritabilidade', 'apetite',\n",
    "    'concentracao', 'fadiga', 'int_sexo', 'quantAmigos'\n",
    "]\n",
    "\n",
    "df[colunas_para_converter] = df[colunas_para_converter].astype('int64')"
   ],
   "id": "a6cd10d242776211",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salvar o DataFrame em um arquivo CSV\n",
    "df.to_csv('dados/com_filtros_datas/6meses/so_suicida_6_meses.csv', index=False)"
   ],
   "id": "dffd3dec7a6ba792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filtrar pelo id_usuario\n",
    "# df = df[df['id_usuario'] == '1022864967872047']"
   ],
   "id": "b0e23ed150a7110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Agrupar por usuário, mês e ano\n",
    "posts_grouped = df.groupby(['id_usuario', 'mes', 'ano']).size().reset_index(name='quantidade')\n",
    "\n",
    "# Adicionar coluna com o período\n",
    "posts_grouped['periodo'] = posts_grouped['mes'].astype(str) + '/' + posts_grouped['ano'].astype(str)"
   ],
   "id": "337f2d80271498b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotar quantidade de posts por usuário",
   "id": "b309a737c28177ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # plotar quantidade de posts por usuario\n",
    "# \n",
    "# # Criar o gráfico de linha para cada usuário\n",
    "# for usuario in posts_grouped['id_usuario'].unique():\n",
    "#     df_usuario = posts_grouped[posts_grouped['id_usuario'] == usuario].copy()\n",
    "# \n",
    "#     # Convertendo a coluna 'periodo' para datetime para garantir a ordenação correta\n",
    "#     df_usuario['periodo'] = pd.to_datetime(df_usuario['periodo'], format='%m/%Y', errors='coerce')\n",
    "# \n",
    "#     # Ordenar os dados por 'periodo'\n",
    "#     df_usuario = df_usuario.sort_values('periodo')\n",
    "# \n",
    "#     # Configurar o gráfico de linha\n",
    "#     plt.figure(figsize=(20, 8))  # Aumentar o tamanho da figura\n",
    "# \n",
    "#     plt.plot(df_usuario['periodo'].dt.strftime('%m/%Y'), df_usuario['quantidade'], marker='o', linestyle='-',\n",
    "#              color='blue')\n",
    "# \n",
    "#     # Adicionar título e rótulos\n",
    "#     plt.title(f'Quantidade de Posts por Mês/Ano - Usuário: {usuario}')\n",
    "#     plt.xlabel('Mês/Ano')\n",
    "#     plt.ylabel('Quantidade de Posts')\n",
    "# \n",
    "#     # Melhorar a legibilidade dos rótulos do eixo X\n",
    "#     plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "# \n",
    "#     # Aumentar o pad dos rótulos do eixo X\n",
    "#     plt.gca().tick_params(axis='x', pad=14)  # Aumenta o espaço entre os rótulos e o eixo\n",
    "# \n",
    "#     # Adicionar grid\n",
    "#     plt.grid(True, axis='y')\n",
    "# \n",
    "#     # Ajustar o layout para evitar sobreposição, com mais padding\n",
    "#     plt.tight_layout(pad=8.0)  # Aumentar o padding geral do layout\n",
    "# \n",
    "#     # Adicionar espaço extra ao layout se necessário\n",
    "#     plt.subplots_adjust(bottom=0.2)  # Adiciona mais espaço abaixo dos rótulos do eixo X\n",
    "# \n",
    "#     # Salvando o gráfico no diretório dados/com_filtros_datas/6meses/graficos\n",
    "#     plt.savefig(f'dados/com_filtros_datas/6meses/graficos/quantidade_posts_{usuario}.png')\n",
    "# \n",
    "#     # Mostrar o gráfico\n",
    "#     plt.show()\n",
    "# \n",
    "#     # Fechar a figura explicitamente para liberar memória\n",
    "#     plt.close()"
   ],
   "id": "99c10501106abed1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Efentuando a limpeza dos dados",
   "id": "44e73a070a35b8a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_stopwords() -> list:\n",
    "    portuguese_ingles_stopwords = []\n",
    "\n",
    "    # Stopwords em português\n",
    "    portugues = [unidecode.unidecode(palavra.lower().replace(\" \", \"\")) for palavra in\n",
    "                 nltk.corpus.stopwords.words('portuguese')]\n",
    "    portuguese_ingles_stopwords.extend(portugues)\n",
    "\n",
    "    # Stopwords em inglês\n",
    "    ingles = [unidecode.unidecode(palavra.lower().replace(\" \", \"\")) for palavra in\n",
    "              nltk.corpus.stopwords.words('english')]\n",
    "    portuguese_ingles_stopwords.extend(ingles)\n",
    "\n",
    "    # Stopwords de diferentes fontes\n",
    "    stopwords_wordcloud = [unidecode.unidecode(palavra.lower().replace(\" \", \"\")) for palavra in STOPWORDS]\n",
    "    portuguese_ingles_stopwords.extend(stopwords_wordcloud)\n",
    "\n",
    "    stopwords_sklearn = [unidecode.unidecode(word.lower().replace(\" \", \"\")) for word in STOP_WORDS]\n",
    "    portuguese_ingles_stopwords.extend(stopwords_sklearn)\n",
    "\n",
    "    # Adicionar stopwords do arquivo customizado\n",
    "    with open('dados/datasets/stopwords-pt.txt', 'r', encoding='utf-8') as words:\n",
    "        custom_stopwords = [unidecode.unidecode(word.lower().strip()) for word in words if word.strip()]\n",
    "    portuguese_ingles_stopwords.extend(custom_stopwords)\n",
    "\n",
    "    # Adicionar nomes\n",
    "    with open('dados/datasets/nomes.txt', 'r', encoding='utf-8') as words:\n",
    "        nomes_stopwords = [unidecode.unidecode(word.lower().strip()) for word in words if word.strip()]\n",
    "    portuguese_ingles_stopwords.extend(nomes_stopwords)\n",
    "\n",
    "    # Remover duplicatas e ordenar a lista\n",
    "    portuguese_ingles_stopwords = list(set(portuguese_ingles_stopwords))\n",
    "    portuguese_ingles_stopwords.sort()\n",
    "\n",
    "    return portuguese_ingles_stopwords\n",
    "\n",
    "\n",
    "def remocao_stopword(string, lista_stopwords) -> str:\n",
    "    a = [i for i in string.split() if i not in lista_stopwords]\n",
    "    return ' '.join(a)\n",
    "\n",
    "\n",
    "def remove_caracteres(text) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = re.compile(r'<.*?>').sub('', text)\n",
    "    text = re.compile(r'[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    text = re.sub(r\"\\$\", \"\", text)\n",
    "    text = re.sub(r\"https?:\\/\\/.*[\\r\\n]*\", \"\", text)\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    text = re.sub(r'https?:\\/\\/[\\r\\n],\"[\\r\\n]\"', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r'[^a-zà-ù ]', ' ', text)\n",
    "    text = re.sub(r'k{2,}', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'j{2,}', '', text, flags=re.IGNORECASE)\n",
    "    text = re.compile(r\"[\"\n",
    "                      u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                      u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                      u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                      u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                      u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                      u\"\\U00002702-\\U000027B0\"\n",
    "                      u\"\\U00002702-\\U000027B0\"\n",
    "                      u\"\\U000024C2-\\U0001F251\"\n",
    "                      u\"\\U0001f926-\\U0001f937\"\n",
    "                      u\"\\U00010000-\\U0010ffff\"\n",
    "                      u\"\\u2640-\\u2642\"\n",
    "                      u\"\\u2600-\\u2B55\"\n",
    "                      u\"\\u200d\"\n",
    "                      u\"\\u23cf\"\n",
    "                      u\"\\u23e9\"\n",
    "                      u\"\\u231a\"\n",
    "                      u\"\\ufe0f\"  # dingbats\n",
    "                      u\"\\u3030\"\n",
    "                      \"]+\", flags=re.UNICODE).sub(r'', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def obter_pos_tag(token) -> str:\n",
    "    if token.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif token.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif token.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif token.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lematizacao(string) -> str:\n",
    "    token = word_tokenize(string)\n",
    "    word_pos_tags = nltk.pos_tag(token)\n",
    "    wl = WordNetLemmatizer()\n",
    "    a = [wl.lemmatize(tag[0], obter_pos_tag(tag[1])) for idx, tag in\n",
    "         enumerate(word_pos_tags)]\n",
    "    return \" \".join(a)\n",
    "\n",
    "\n",
    "def preprocessamento_texto(texto_limpo) -> str:\n",
    "    lista_stopwords = get_stopwords()\n",
    "    texto_limpo = remove_caracteres(texto_limpo)\n",
    "    texto_limpo = remocao_stopword(texto_limpo, lista_stopwords)\n",
    "    texto_limpo = lematizacao(texto_limpo)\n",
    "    return texto_limpo"
   ],
   "id": "aceb4344b9b49f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['postMessageLimpo'] = df['postMessage'].fillna('').apply(preprocessamento_texto)\n",
    "df.head()\n",
    "corpus = df['postMessageLimpo'].tolist()"
   ],
   "id": "55003b9f9e6eaac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ],
   "id": "77e1f726987e810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Carregar stopwords em português para os TF-IDF e Bag of Words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('portuguese')"
   ],
   "id": "fc92b46e4febeaf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar o vetorizador TF-IDF com parâmetros ajustados\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    max_features=None,\n",
    "    max_df=0.40,\n",
    "    min_df=5,\n",
    "    ngram_range=(1, 1),\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "corpus_tfidf = df['postMessageLimpo'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus_tfidf)\n",
    "\n",
    "# Obter as palavras\n",
    "palavras_tfidf = vectorizer.get_feature_names_out()\n",
    "# Lista para armazenar os resultados\n",
    "resultados_tfidf = []\n",
    "\n",
    "# Iterar sobre cada usuário\n",
    "for usuario in df['id_usuario'].unique():\n",
    "    # Filtrar os textos do usuário\n",
    "    indices_usuario = df[df['id_usuario'] == usuario].index\n",
    "    if len(indices_usuario) > 0:\n",
    "        # Extrair as palavras com maior score TF-IDF para o usuário\n",
    "        user_tfidf = tfidf_matrix[indices_usuario]\n",
    "        user_tfidf_mean = np.asarray(user_tfidf.mean(axis=0)).flatten()\n",
    "\n",
    "        # Obter os índices das 10 palavras com maior score\n",
    "        top_10_indices = user_tfidf_mean.argsort()[-10:][::-1]\n",
    "\n",
    "        # Adicionar as palavras e seus scores à lista de resultados\n",
    "        for index in top_10_indices:\n",
    "            resultados_tfidf.append({\n",
    "                'id_usuario': usuario,\n",
    "                'palavra': palavras_tfidf[index],\n",
    "                'score': user_tfidf_mean[index]\n",
    "            })\n",
    "\n",
    "# Converter a lista de resultados em DataFrame\n",
    "resultados_df_tfidf = pd.DataFrame(resultados_tfidf)\n",
    "resultados_df_tfidf.to_csv('dados/com_filtros_datas/6meses/so_suicida_resultados_tfidf_unigramas.csv', index=False)\n",
    "\n",
    "print(resultados_df_tfidf)"
   ],
   "id": "2f6d54daf418e3e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Usando o algoritmo Bag of Words",
   "id": "c6ce4c689fd09eab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar o vetorizador Bag of Words com parâmetros ajustados\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    ngram_range=(1, 1),\n",
    "    max_df=0.85,\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "corpus_bow = df['postMessageLimpo'].tolist()\n",
    "bow_matrix = vectorizer.fit_transform(corpus_bow)\n",
    "\n",
    "palavras_bow = vectorizer.get_feature_names_out()\n",
    "\n",
    "resultados_bow = []\n",
    "\n",
    "for usuario in df['id_usuario'].unique():\n",
    "    indices_usuario = df[df['id_usuario'] == usuario].index\n",
    "    if len(indices_usuario) > 0:\n",
    "        user_bow = bow_matrix[indices_usuario]\n",
    "        user_bow_sum = np.asarray(user_bow.sum(axis=0)).flatten()\n",
    "\n",
    "        top_10_indices_bow = user_bow_sum.argsort()[-10:][::-1]\n",
    "\n",
    "        for index in top_10_indices_bow:\n",
    "            resultados_bow.append({\n",
    "                'id_usuario': usuario,\n",
    "                'palavra': palavras_bow[index],\n",
    "                'contagem': user_bow_sum[index]\n",
    "            })\n",
    "\n",
    "# Converter a lista de resultados em DataFrame\n",
    "resultados_df_bow = pd.DataFrame(resultados_bow)\n",
    "resultados_df_bow.to_csv('dados/com_filtros_datas/6meses/so_suicida_resultados_bow_unigramas.csv', index=False)\n",
    "\n",
    "print(resultados_df_bow)"
   ],
   "id": "2a1dc735f1d6e111",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
