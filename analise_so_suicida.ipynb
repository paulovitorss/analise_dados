{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importe as bibliotecas necessárias",
   "id": "bc14dafce2caf907"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:31.483082Z",
     "start_time": "2024-09-17T01:50:31.478715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "# Instalando as bibliotecas necessárias\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install pymongo\n",
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install wordcloud\n",
    "%pip install spacy\n",
    "%pip install matplotlib\n",
    "%pip install numpy==1.26.4\n",
    "%pip install -U scikit-learn\n",
    "%pip install unidecode\n",
    "'''"
   ],
   "id": "7f2d74b00c76fd40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Instalando as bibliotecas necessárias\\n%pip install -U pip setuptools wheel\\n%pip install pymongo\\n%pip install pandas\\n%pip install nltk\\n%pip install wordcloud\\n%pip install spacy\\n%pip install matplotlib\\n%pip install numpy==1.26.4\\n%pip install -U scikit-learn\\n%pip install unidecode\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importando as bibliotecas",
   "id": "2bf9d9363b7b99f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:34.865978Z",
     "start_time": "2024-09-17T01:50:31.526626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "from datetime import datetime\n",
    "from db import connection_db as conndb\n",
    "from db import filters\n",
    "from utils import plot_graphs\n",
    "from utils.text_treatment import TextTreatment\n",
    "from utils.text_vectorization import TextVectorization\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from utils.nuvem_palavras import NuvemPalavras\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "4761db26da7a2327",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:34.950669Z",
     "start_time": "2024-09-17T01:50:34.944924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mongo_connection = conndb.MongoDBConnection(uri='mongodb://localhost:27017/', database_name='dadosVivamente',\n",
    "                                            collection_name='dadosSemFiltros')\n",
    "mongo_connection.connect()\n",
    "collection = mongo_connection.collection"
   ],
   "id": "7a6bb32be9aeb75a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão estabelecida com sucesso ao banco de dados.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:35.109215Z",
     "start_time": "2024-09-17T01:50:35.012183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collection_filters = filters.CollectionFilters(collection)\n",
    "collection_filters.apply_pipeline1('dadosComFiltrosIniciais')\n",
    "collection_filters.apply_pipeline2(7, 2, 'posts7anos2anos')\n",
    "collection_filters.apply_pipeline3('postsComBDIAndInfos')\n",
    "collection_filters.apply_pipeline4('postsComBDIAndInfosFiltroDataPosts')\n",
    "data_inicio = datetime(2017, 12, 1)\n",
    "data_fim = data_inicio - relativedelta(months=6)\n",
    "collection_filters.apply_pipeline5('postsFiltradosPorData', data_inicio, data_fim)\n",
    "collection_filters.quant_users_cat('suicida', '$eq', '3')\n",
    "collection_filters.count_users_by_gender('suicida', '$eq', '3', 'M')\n",
    "collection_filters.count_users_by_gender('suicida', '$eq', '3', 'F')\n",
    "collection = collection_filters.collection"
   ],
   "id": "ba5a47bd08e116ad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:A coleção já existe: dadosComFiltrosIniciais\n",
      "INFO:root:A coleção já existe: posts7anos2anos\n",
      "INFO:root:A coleção já existe: postsComBDIAndInfos\n",
      "INFO:root:A coleção já existe: postsComBDIAndInfosFiltroDataPosts\n",
      "INFO:root:A coleção já existe: postsFiltradosPorData\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Usuários: 58\n",
      "Quantidade de usuários M: 11\n",
      "Quantidade de usuários F: 47\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:35.125043Z",
     "start_time": "2024-09-17T01:50:35.123073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtrando documentos com o atributo maior que 3\n",
    "filtro = {\"nivel\": {\"$eq\": 2}}\n",
    "documentos = collection.find(filtro)"
   ],
   "id": "ea19f91952d67bca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:35.683780Z",
     "start_time": "2024-09-17T01:50:35.164933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformando os documentos em um DataFrame\n",
    "df = pd.DataFrame(list(documentos))\n",
    "df.head()"
   ],
   "id": "8e80f1ac50e27240",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        _id  idade sexo        id_usuario  nivel pessimismo  \\\n",
       "0  59c325925fef19001e03ae70     33    F  1358116567556711    2.0          1   \n",
       "1  59c325925fef19001e03ae71     33    F  1358116567556711    2.0          1   \n",
       "2  59c325925fef19001e03ae72     33    F  1358116567556711    2.0          1   \n",
       "3  59c325925fef19001e03ae73     33    F  1358116567556711    2.0          1   \n",
       "4  59c325925fef19001e03ae74     33    F  1358116567556711    2.0          1   \n",
       "\n",
       "  tristeza fracasso prazer culpa  ... quantAmigos  \\\n",
       "0        1        0      0     1  ...        1099   \n",
       "1        1        0      0     1  ...        1099   \n",
       "2        1        0      0     1  ...        1099   \n",
       "3        1        0      0     1  ...        1099   \n",
       "4        1        0      0     1  ...        1099   \n",
       "\n",
       "                                         postMessage  \\\n",
       "0                                                ❤❤❤   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3      #pescadores_br #caceres #riosepotuba #fishing   \n",
       "4  Parabéns Giulia!! O tão esperado #DiaDaAlta ch...   \n",
       "\n",
       "                                           postStory    postCreated_time  \\\n",
       "0                       Elisa Lacal shared a memory. 2017-09-20 13:43:35   \n",
       "1  Elisa Lacal shared Colégio Master :: Oficial :... 2017-09-16 10:23:09   \n",
       "2  Ellen Bueno added 4 new photos — with Marcus A... 2017-09-10 22:09:50   \n",
       "3  Murilo Alves Gonçalves Dos Santos is with Marc... 2017-09-10 20:05:32   \n",
       "4  REDEORTO Várzea Grande is feeling blissful wit... 2017-09-05 20:05:46   \n",
       "\n",
       "    diaDaSemana hora minutos diaDoMes mes   ano  \n",
       "0  Quarta-feira   13      43       20   9  2017  \n",
       "1        Sábado   10      23       16   9  2017  \n",
       "2       Domingo   22       9       10   9  2017  \n",
       "3       Domingo   20       5       10   9  2017  \n",
       "4   Terça-feira   20       5        5   9  2017  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>idade</th>\n",
       "      <th>sexo</th>\n",
       "      <th>id_usuario</th>\n",
       "      <th>nivel</th>\n",
       "      <th>pessimismo</th>\n",
       "      <th>tristeza</th>\n",
       "      <th>fracasso</th>\n",
       "      <th>prazer</th>\n",
       "      <th>culpa</th>\n",
       "      <th>...</th>\n",
       "      <th>quantAmigos</th>\n",
       "      <th>postMessage</th>\n",
       "      <th>postStory</th>\n",
       "      <th>postCreated_time</th>\n",
       "      <th>diaDaSemana</th>\n",
       "      <th>hora</th>\n",
       "      <th>minutos</th>\n",
       "      <th>diaDoMes</th>\n",
       "      <th>mes</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59c325925fef19001e03ae70</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1358116567556711</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1099</td>\n",
       "      <td>❤❤❤</td>\n",
       "      <td>Elisa Lacal shared a memory.</td>\n",
       "      <td>2017-09-20 13:43:35</td>\n",
       "      <td>Quarta-feira</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59c325925fef19001e03ae71</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1358116567556711</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elisa Lacal shared Colégio Master :: Oficial :...</td>\n",
       "      <td>2017-09-16 10:23:09</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59c325925fef19001e03ae72</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1358116567556711</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellen Bueno added 4 new photos — with Marcus A...</td>\n",
       "      <td>2017-09-10 22:09:50</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59c325925fef19001e03ae73</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1358116567556711</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1099</td>\n",
       "      <td>#pescadores_br #caceres #riosepotuba #fishing</td>\n",
       "      <td>Murilo Alves Gonçalves Dos Santos is with Marc...</td>\n",
       "      <td>2017-09-10 20:05:32</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59c325925fef19001e03ae74</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1358116567556711</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1099</td>\n",
       "      <td>Parabéns Giulia!! O tão esperado #DiaDaAlta ch...</td>\n",
       "      <td>REDEORTO Várzea Grande is feeling blissful wit...</td>\n",
       "      <td>2017-09-05 20:05:46</td>\n",
       "      <td>Terça-feira</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:35.781862Z",
     "start_time": "2024-09-17T01:50:35.731563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df.dtypes)\n",
    "# Lista de colunas que precisam ser convertidas\n",
    "colunas_para_converter = [\n",
    "    'pessimismo', 'tristeza', 'fracasso', 'prazer', 'culpa', 'punicao', 'estima',\n",
    "    'critica', 'suicida', 'choro', 'agitacao', 'interesse', 'indecisao',\n",
    "    'desvalorizacao', 'energia', 'sono', 'irritabilidade', 'apetite',\n",
    "    'concentracao', 'fadiga', 'int_sexo', 'quantAmigos'\n",
    "]\n",
    "\n",
    "df[colunas_para_converter] = df[colunas_para_converter].astype('int64')"
   ],
   "id": "a6cd10d242776211",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id                         object\n",
      "idade                        int64\n",
      "sexo                        object\n",
      "id_usuario                  object\n",
      "nivel                      float64\n",
      "pessimismo                  object\n",
      "tristeza                    object\n",
      "fracasso                    object\n",
      "prazer                      object\n",
      "culpa                       object\n",
      "punicao                     object\n",
      "estima                      object\n",
      "critica                     object\n",
      "suicida                     object\n",
      "choro                       object\n",
      "agitacao                    object\n",
      "interesse                   object\n",
      "indecisao                   object\n",
      "desvalorizacao              object\n",
      "energia                     object\n",
      "sono                        object\n",
      "irritabilidade              object\n",
      "apetite                     object\n",
      "concentracao                object\n",
      "fadiga                      object\n",
      "int_sexo                    object\n",
      "quantAmigos                 object\n",
      "postMessage                 object\n",
      "postStory                   object\n",
      "postCreated_time    datetime64[ns]\n",
      "diaDaSemana                 object\n",
      "hora                         int64\n",
      "minutos                      int64\n",
      "diaDoMes                     int64\n",
      "mes                          int64\n",
      "ano                          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:36.151922Z",
     "start_time": "2024-09-17T01:50:35.825825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Salvar o DataFrame em um arquivo CSV\n",
    "df.to_csv('dados/com_filtros_datas/6meses/so_suicida_6_meses.csv', index=False)"
   ],
   "id": "dffd3dec7a6ba792",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:36.263703Z",
     "start_time": "2024-09-17T01:50:36.249519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Agrupar por usuário, mês e ano\n",
    "posts_grouped = df.groupby(['id_usuario', 'mes', 'ano']).size().reset_index(name='quantidade')\n",
    "\n",
    "# Adicionar coluna com o período e converter para datetime\n",
    "posts_grouped['periodo'] = pd.to_datetime(posts_grouped['mes'].astype(str) + '/' + posts_grouped['ano'].astype(str),\n",
    "                                          format='%m/%Y')\n",
    "\n",
    "# Deve retornar 0 se a conversão foi bem-sucedida.\n",
    "print(posts_grouped['periodo'].isnull().sum())\n",
    "\n",
    "posts_grouped.dtypes"
   ],
   "id": "337f2d80271498b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_usuario            object\n",
       "mes                    int64\n",
       "ano                    int64\n",
       "quantidade             int64\n",
       "periodo       datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotar quantidade de posts por usuário",
   "id": "b309a737c28177ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:36.312635Z",
     "start_time": "2024-09-17T01:50:36.310844Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_graphs.PlotGraphs().plot_posts_per_user(posts_grouped, 'dados/com_filtros_datas/6meses/graficos')",
   "id": "723527524f4964ec",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Efentuando a limpeza dos dados",
   "id": "44e73a070a35b8a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:38.337464Z",
     "start_time": "2024-09-17T01:50:36.393717Z"
    }
   },
   "cell_type": "code",
   "source": "tratamento_texto = TextTreatment()",
   "id": "334cc9686a30bde0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulovss/Documentos/projects/python/analise_dados/venv/lib/python3.12/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/paulovss/Documentos/projects/python/analise_dados/venv/lib/python3.12/site-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/paulovss/Documentos/projects/python/analise_dados/venv/lib/python3.12/site-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/paulovss/Documentos/projects/python/analise_dados/venv/lib/python3.12/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/home/paulovss/Documentos/projects/python/analise_dados/venv/lib/python3.12/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/paulovss/Documentos/projects/python/analise_dados/venv/lib/python3.12/site-packages/stanza/models/lemma/trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:38.524565Z",
     "start_time": "2024-09-17T01:50:38.366191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['postMessage'] = df['postMessage'].fillna('').astype(str)\n",
    "resultado = tratamento_texto.finds_pandas_words(df['postMessage'], 'dados/datasets/nomes_medicamentos_antidepressivos.txt')\n",
    "print(resultado)"
   ],
   "id": "7133eda0bdba4b8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "34509    False\n",
      "34510    False\n",
      "34511    False\n",
      "34512    False\n",
      "34513    False\n",
      "Name: postMessage, Length: 34514, dtype: bool\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T01:50:47.765671Z",
     "start_time": "2024-09-17T01:50:38.594268Z"
    }
   },
   "cell_type": "code",
   "source": "tratamento_texto.finds_fuzzy_words(df['postMessage'], 'dados/datasets/nomes_medicamentos_antidepressivos.txt')",
   "id": "700a4f5cdf690a3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['postMessageLimpo'] = df['postMessage'].fillna('').progress_apply(\n",
    "    lambda texto: tratamento_texto.preprocessamento_texto(texto) if texto else '')"
   ],
   "id": "1f4ea101d719870e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Exibir apenas as colunas postMessage e postMessageLimpo\n",
    "df[['postMessage', 'postMessageLimpo']].head()"
   ],
   "id": "61dbc3fbbde3d1f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Carregar stopwords em português para os TF-IDF e Bag of Words\n",
    "stop_words = stopwords.words('portuguese')"
   ],
   "id": "fc92b46e4febeaf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_vectorizer = TextVectorization(df, stop_words)\n",
    "# Vetorização TF-IDF\n",
    "resultados_tfidf = text_vectorizer.tfidf_vectorization(\n",
    "    'dados/com_filtros_datas/6meses/so_suicida_resultados_tfidf_unigramas.csv', 0.60, 2,\n",
    "    (1, 1))\n",
    "\n",
    "# Vetorização Bag of Words\n",
    "resultados_bow = text_vectorizer.bag_of_words_vectorization(\n",
    "    'dados/com_filtros_datas/6meses/so_suicida_resultados_bow_unigramas.csv',\n",
    "    0.85, 5, (1, 1))"
   ],
   "id": "e09778ab20fe9cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_vectorizer.plot_top_words(resultados_tfidf, column='score', title='Top 10 Palavras TF-IDF')\n",
    "text_vectorizer.plot_top_words(resultados_bow, column='contagem', title='Top 10 Palavras Bag of Words')"
   ],
   "id": "be9df1cdb07eaaa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frequencias_bow = dict(zip(resultados_bow['palavra'], resultados_bow['contagem']))\n",
    "\n",
    "# Gerar e plotar a nuvem de palavras\n",
    "NuvemPalavras.plot_nuvem_palavras(frequencias_bow)"
   ],
   "id": "cfbacce53d8735d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frequencias_tfidf = dict(zip(resultados_tfidf['palavra'], resultados_tfidf['score']))\n",
    "\n",
    "# Gerar e plotar a nuvem de palavras\n",
    "NuvemPalavras.plot_nuvem_palavras(frequencias_tfidf)"
   ],
   "id": "2b91068a01dc83aa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
